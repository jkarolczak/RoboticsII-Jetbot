{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7zHfyt-XtLT"
   },
   "source": [
    "# Changelog\n",
    "1. 02.06, Jacek - add dataset, dataloader, model prototype, training frames\n",
    "2. 03.06, Jacek - fix seed(s), add train-test split, full train-loop, resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rnFsqbP6wSt7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from copy import deepcopy\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZHSMTSi3BmsN"
   },
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "\n",
    "# define your path below\n",
    "# DATASET_PATH = ... # Ania\n",
    "# DATASET_PATH = ... # Witek\n",
    "DATASET_PATH = 'dataset/'  # Jacek\n",
    "\n",
    "# hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "NUM_WORKERS = 8  # in collab shouldn't exceed 2\n",
    "TRAIN_SET_SIZE = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TEikNh9bW_s0"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VN82Vw_KAdqw"
   },
   "outputs": [],
   "source": [
    "class AugmentedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path: str) -> None:\n",
    "        self.path = path\n",
    "        self.dirs = [d for d in os.listdir(self.path) if os.path.isdir(os.path.join(self.path, d))]\n",
    "        self.items = self._get_file_target_map()\n",
    "\n",
    "    def _get_file_target_map(self) -> List[Tuple[str, Tuple[float, float]]]:\n",
    "        result = []\n",
    "        for dir in self.dirs:\n",
    "            labels = pd.read_csv(f'{self.path}/{dir}.csv', header=None, index_col=0, names=['speed', 'turn'])\n",
    "            for file_name in os.listdir(os.path.join(self.path, dir)):\n",
    "                file_path = os.path.join(self.path, dir, file_name)\n",
    "                photo_id = int(re.search(r'\\d+', file_name).group())\n",
    "                if photo_id in labels.index:\n",
    "                    target = labels.loc[photo_id]\n",
    "                    result.append((file_path, (target['speed'], target['turn'])))\n",
    "        return result\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        path, target = self.items[idx]\n",
    "        img = torch.tensor(np.asarray(Image.open(path)), dtype=torch.float32)\n",
    "        target = torch.tensor(target, dtype=torch.float32)\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jVJeCE8pO38l"
   },
   "outputs": [],
   "source": [
    "dataset = AugmentedDataset(DATASET_PATH)\n",
    "train_dataset, test_dataset = deepcopy(dataset), deepcopy(dataset)\n",
    "train_dataset.items, test_dataset.items = train_test_split(dataset.items, train_size=TRAIN_SET_SIZE, shuffle=True,\n",
    "                                                           random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zfu0F6k1Um9v"
   },
   "outputs": [],
   "source": [
    "train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W-AUz2BvSQcl"
   },
   "outputs": [],
   "source": [
    "x, y = train_dataset[0]\n",
    "print(f'x: {type(x)}, {x.shape}')\n",
    "print(f'y: {type(y)}, {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CegAWRiBSQC3"
   },
   "outputs": [],
   "source": [
    "x, y = next(iter(train))\n",
    "print(f'x: {type(x)}, {x.shape}')\n",
    "print(f'y: {type(y)}, {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5mw2wrrHl-px"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.resnet18 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False)\n",
    "        self.resnet18.fc = nn.Linear(in_features=512, out_features=2, bias=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = torch.movedim(x, -1, -3)\n",
    "        x = self.resnet18(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0KsSWdmZNr2"
   },
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.cuda()\n",
    "model = torch.jit.script(model)\n",
    "model(next(iter(train))[0].to(torch.device('cuda'))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3hk-8VG8Tajg"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5VE9Unb_UKXN"
   },
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f'epoch {epoch}')\n",
    "    train_loss_history, test_loss_history = [], []\n",
    "\n",
    "    model.train()\n",
    "    for i, (x_train, y_train) in enumerate(train):\n",
    "        print(i)\n",
    "        x_train = x_train.to(torch.device('cuda'))\n",
    "        y_train = y_train.to(torch.device('cuda'))\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(x_train)\n",
    "        loss = criterion(y_hat, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_history.append(float(loss.detach().cpu()))\n",
    "    print(f'train loss: {sum(train_loss_history) / len(train_loss_history)}')\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x_test, y_test in test:\n",
    "            x_test = x_test.to(torch.device('cuda'))\n",
    "            y_test = y_test.to(torch.device('cuda'))\n",
    "            y_hat = model(x_test)\n",
    "            loss = criterion(y_hat, y_test)\n",
    "            test_loss_history.append(float(loss.detach().cpu()))\n",
    "    print(f'test loss: {sum(test_loss_history) / len(test_loss_history)}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "jetbot-dl-model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}