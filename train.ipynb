{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rnFsqbP6wSt7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from copy import deepcopy\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZHSMTSi3BmsN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "\n",
    "# define your path below\n",
    "# DATASET_PATH = ... # Ania\n",
    "# DATASET_PATH = ... # Witek\n",
    "DATASET_PATH = 'dataset/'  # Jacek\n",
    "\n",
    "# hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "NUM_WORKERS = 1\n",
    "TRAIN_SET_SIZE = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TEikNh9bW_s0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VN82Vw_KAdqw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class StorageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path: str) -> None:\n",
    "        self.path = path\n",
    "        self.dirs = [d for d in os.listdir(self.path) if os.path.isdir(os.path.join(self.path, d))]\n",
    "        self.items = self._get_file_target_map()\n",
    "\n",
    "    def _get_file_target_map(self) -> List[Tuple[str, Tuple[float, float]]]:\n",
    "        result = []\n",
    "        for dir in self.dirs:\n",
    "            labels = pd.read_csv(f'{self.path}/{dir}.csv', header=None, index_col=0, names=['speed', 'turn'])\n",
    "            for file_name in os.listdir(os.path.join(self.path, dir)):\n",
    "                file_path = os.path.join(self.path, dir, file_name)\n",
    "                photo_id = int(re.search(r'\\d+', file_name).group())\n",
    "                if photo_id in labels.index:\n",
    "                    target = labels.loc[photo_id]\n",
    "                    result.append((file_path, (target['speed'], target['turn'], photo_id)))\n",
    "        return result\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        path, target = self.items[idx]\n",
    "        img = torch.tensor(np.asarray(Image.open(path)), dtype=torch.float32)\n",
    "        target = torch.tensor(target[:2], dtype=torch.float32)\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MemoryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path: str) -> None:\n",
    "        self.path = path\n",
    "        self.dirs = [d for d in os.listdir(self.path) if os.path.isdir(os.path.join(self.path, d))]\n",
    "        self.items = self._get_file_target_map()\n",
    "\n",
    "    def _get_file_target_map(self) -> List[Tuple[str, Tuple[float, float]]]:\n",
    "        result = []\n",
    "        for dir in self.dirs:\n",
    "            labels = pd.read_csv(f'{self.path}/{dir}.csv', header=None, index_col=0, names=['speed', 'turn'])\n",
    "            for file_name in os.listdir(os.path.join(self.path, dir)):\n",
    "                file_path = os.path.join(self.path, dir, file_name)\n",
    "                photo_id = int(re.search(r'\\d+', file_name).group())\n",
    "                if photo_id in labels.index:\n",
    "                    target = labels.loc[photo_id]\n",
    "                    img = Image.open(file_path)\n",
    "                    result.append((img, (target['speed'], target['turn'], photo_id)))\n",
    "        return result\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        img, target = self.items[idx]\n",
    "        img = torch.tensor(np.asarray(img), dtype=torch.float32)\n",
    "        target = torch.tensor(target[:2], dtype=torch.float32)\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_split(dataset: Union[StorageDataset, MemoryDataset], train_size: float = 0.8, shuffle: bool = True):\n",
    "    train_keys, test_keys = set(), set()\n",
    "    train_items, test_items = list(), list()\n",
    "    for item in dataset.items:\n",
    "        key = item[1][2]\n",
    "        if key in train_keys:\n",
    "            train_items.append(item)\n",
    "        elif key in test_keys:\n",
    "            test_items.append(item)\n",
    "        else:\n",
    "            if np.random.random() < train_size:\n",
    "                train_keys.add(key)\n",
    "                train_items.append(item)\n",
    "            else:\n",
    "                test_keys.add(key)\n",
    "                test_items.append(item)\n",
    "    train, test = deepcopy(dataset), deepcopy(dataset)\n",
    "    train.items, test.items = train_items, test_items\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jVJeCE8pO38l",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = StorageDataset(DATASET_PATH)\n",
    "# dataset = MemoryDataset(DATASET_PATH)\n",
    "train_dataset, test_dataset = train_test_split(dataset, train_size=TRAIN_SET_SIZE, shuffle=True)\n",
    "train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5mw2wrrHl-px",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.resnet18 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "        self.resnet18.fc = nn.Linear(in_features=512, out_features=2, bias=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.resnet18(x)\n",
    "        x = torch.clamp(x, min=-1.0, max=1.0)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0KsSWdmZNr2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.cuda()\n",
    "model = torch.jit.script(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3hk-8VG8Tajg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5VE9Unb_UKXN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_len = len(train_dataset)\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 224, 224, device='cuda')\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'epoch {epoch}')\n",
    "    best_loss = np.inf\n",
    "    train_loss_history, test_loss_history = [], []\n",
    "\n",
    "    model.train()\n",
    "    for i, (x_train, y_train) in enumerate(train):\n",
    "        if not i % 5:\n",
    "            print(f'{i}/{int(train_len / BATCH_SIZE)}', end='\\r')\n",
    "        x_train = torch.movedim(x_train, -1, -3)\n",
    "        x_train = x_train.to(torch.device('cuda'))\n",
    "        y_train = y_train.to(torch.device('cuda'))\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(x_train)\n",
    "        loss = criterion(y_hat, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_history.append(float(loss.detach().cpu()))\n",
    "    print(f'train loss: {sum(train_loss_history) / len(train_loss_history)}')\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x_test, y_test in test:\n",
    "            x_test = torch.movedim(x_test, -1, -3)\n",
    "            x_test = x_test.to(torch.device('cuda'))\n",
    "            y_test = y_test.to(torch.device('cuda'))\n",
    "            y_hat = model(x_test)\n",
    "            loss = criterion(y_hat, y_test)\n",
    "            test_loss_history.append(float(loss.detach().cpu()))\n",
    "    test_loss = sum(test_loss_history) / len(test_loss_history)\n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        _ = torch.onnx.export(model, dummy_input, f'models/resnet18_{epoch}_{test_loss:.4f}.onnx', verbose=False)\n",
    "        print(f'test loss: {test_loss} (best, saving model)')\n",
    "    else:\n",
    "        print(f'test loss: {test_loss}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "jetbot-dl-model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}