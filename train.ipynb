{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rnFsqbP6wSt7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from copy import deepcopy\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZHSMTSi3BmsN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "\n",
    "# define your path below\n",
    "# DATASET_PATH = ... # Ania\n",
    "# DATASET_PATH = ... # Witek\n",
    "DATASET_PATH = 'dataset/'  # Jacek\n",
    "\n",
    "# hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "NUM_WORKERS = 1\n",
    "TRAIN_SET_SIZE = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TEikNh9bW_s0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VN82Vw_KAdqw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class StorageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path: str) -> None:\n",
    "        self.path = path\n",
    "        self.dirs = [d for d in os.listdir(self.path) if os.path.isdir(os.path.join(self.path, d))]\n",
    "        self.items = self._get_file_target_map()\n",
    "\n",
    "    def _get_file_target_map(self) -> List[Tuple[str, Tuple[float, float]]]:\n",
    "        result = []\n",
    "        for dir in self.dirs:\n",
    "            labels = pd.read_csv(f'{self.path}/{dir}.csv', header=None, index_col=0, names=['speed', 'turn'])\n",
    "            for file_name in os.listdir(os.path.join(self.path, dir)):\n",
    "                file_path = os.path.join(self.path, dir, file_name)\n",
    "                photo_id = int(re.search(r'\\d+', file_name).group())\n",
    "                if photo_id in labels.index:\n",
    "                    target = labels.loc[photo_id]\n",
    "                    result.append((file_path, (target['speed'], target['turn'], photo_id)))\n",
    "        return result\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        path, target = self.items[idx]\n",
    "        img = torch.tensor(np.asarray(Image.open(path)), dtype=torch.float32)\n",
    "        target = torch.tensor(target[:2], dtype=torch.float32)\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MemoryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path: str) -> None:\n",
    "        self.path = path\n",
    "        self.dirs = [d for d in os.listdir(self.path) if os.path.isdir(os.path.join(self.path, d))]\n",
    "        self.items = self._get_file_target_map()\n",
    "\n",
    "    def _get_file_target_map(self) -> List[Tuple[str, Tuple[float, float]]]:\n",
    "        result = []\n",
    "        for dir in self.dirs:\n",
    "            labels = pd.read_csv(f'{self.path}/{dir}.csv', header=None, index_col=0, names=['speed', 'turn'])\n",
    "            for file_name in os.listdir(os.path.join(self.path, dir)):\n",
    "                file_path = os.path.join(self.path, dir, file_name)\n",
    "                photo_id = int(re.search(r'\\d+', file_name).group())\n",
    "                if photo_id in labels.index:\n",
    "                    target = labels.loc[photo_id]\n",
    "                    img = Image.open(file_path)\n",
    "                    result.append((img, (target['speed'], target['turn'], photo_id)))\n",
    "        return result\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        img, target = self.items[idx]\n",
    "        img = torch.tensor(np.asarray(img), dtype=torch.float32)\n",
    "        target = torch.tensor(target[:2], dtype=torch.float32)\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_split(dataset: Union[StorageDataset, MemoryDataset], train_size: float = 0.8, shuffle: bool = True):\n",
    "    train_keys, test_keys = set(), set()\n",
    "    train_items, test_items = list(), list()\n",
    "    for item in dataset.items:\n",
    "        key = item[1][2]\n",
    "        if key in train_keys:\n",
    "            train_items.append(item)\n",
    "        elif key in test_keys:\n",
    "            test_items.append(item)\n",
    "        else:\n",
    "            if np.random.random() < train_size:\n",
    "                train_keys.add(key)\n",
    "                train_items.append(item)\n",
    "            else:\n",
    "                test_keys.add(key)\n",
    "                test_items.append(item)\n",
    "    train, test = deepcopy(dataset), deepcopy(dataset)\n",
    "    train.items, test.items = train_items, test_items\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "dataset = StorageDataset(DATASET_PATH)\n",
    "# dataset = MemoryDataset(DATASET_PATH)\n",
    "train_dataset, test_dataset = train_test_split(dataset, train_size=TRAIN_SET_SIZE, shuffle=True)\n",
    "train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.resnet34 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\n",
    "        self.resnet34.fc = nn.Linear(in_features=512, out_features=2, bias=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.resnet34(x)\n",
    "        x = torch.clamp(x, min=-1.0, max=1.0)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/witold/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "model.cuda()\n",
    "model = torch.jit.script(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.MSELoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "train loss: 0.12408052838852586\n",
      "test loss: 0.10696464887466924 (best, saving model)\n",
      "epoch 1\n",
      "train loss: 0.09186236290967444\n",
      "test loss: 0.10006776303052903 (best, saving model)\n",
      "epoch 2\n",
      "train loss: 0.073705247739688\n",
      "test loss: 0.08551592744629959 (best, saving model)\n",
      "epoch 3\n",
      "train loss: 0.04544524693404976\n",
      "test loss: 0.09051422178745269 (best, saving model)\n",
      "epoch 4\n",
      "train loss: 0.02907820379877269\n",
      "test loss: 0.08762545351838244 (best, saving model)\n",
      "epoch 5\n",
      "train loss: 0.021083670468734845\n",
      "test loss: 0.08710602706876294 (best, saving model)\n",
      "epoch 6\n",
      "train loss: 0.02583498298642234\n",
      "test loss: 0.08503638444275692 (best, saving model)\n",
      "epoch 7\n",
      "train loss: 0.015340925441525969\n",
      "test loss: 0.08878328229846626 (best, saving model)\n",
      "epoch 8\n",
      "train loss: 0.06929323818564179\n",
      "test loss: 0.15558762090473338 (best, saving model)\n",
      "epoch 9\n",
      "train loss: 0.07902551877001922\n",
      "test loss: 0.08930675790741525 (best, saving model)\n",
      "epoch 10\n",
      "train loss: 0.04252458330592045\n",
      "test loss: 0.1032707593821246 (best, saving model)\n",
      "epoch 11\n",
      "train loss: 0.03269847525559642\n",
      "test loss: 0.09635507127848164 (best, saving model)\n",
      "epoch 12\n",
      "train loss: 0.01637603173515311\n",
      "test loss: 0.09548811956212439 (best, saving model)\n",
      "epoch 13\n",
      "train loss: 0.011639571502702919\n",
      "test loss: 0.09004563294864934 (best, saving model)\n",
      "epoch 14\n",
      "train loss: 0.012127265858511576\n",
      "test loss: 0.09782623008921229 (best, saving model)\n",
      "epoch 15\n",
      "train loss: 0.017067649722841735\n",
      "test loss: 0.10997988180867557 (best, saving model)\n",
      "epoch 16\n",
      "train loss: 0.010186336696602903\n",
      "test loss: 0.10938735948554401 (best, saving model)\n",
      "epoch 17\n",
      "40/566\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [11]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     21\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     22\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m---> 23\u001B[0m     train_loss_history\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mfloat\u001B[39m(\u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetach\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcpu\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m))\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28msum\u001B[39m(train_loss_history) \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(train_loss_history)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     26\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train_len = len(train_dataset)\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 224, 224, device='cuda')\n",
    "os.makedirs('models', exist_ok=True)\n",
    "best_loss = np.inf\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'epoch {epoch}')\n",
    "    train_loss_history, test_loss_history = [], []\n",
    "\n",
    "    model.train()\n",
    "    for i, (x_train, y_train) in enumerate(train):\n",
    "        if not i % 5:\n",
    "            print(f'{i}/{int(train_len / BATCH_SIZE)}', end='\\r')\n",
    "        x_train = torch.movedim(x_train, -1, -3)\n",
    "        x_train = x_train.to(torch.device('cuda'))\n",
    "        y_train = y_train.to(torch.device('cuda'))\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(x_train)\n",
    "        loss = criterion(y_hat, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_history.append(float(loss.detach().cpu()))\n",
    "    print(f'train loss: {sum(train_loss_history) / len(train_loss_history)}')\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x_test, y_test in test:\n",
    "            x_test = torch.movedim(x_test, -1, -3)\n",
    "            x_test = x_test.to(torch.device('cuda'))\n",
    "            y_test = y_test.to(torch.device('cuda'))\n",
    "            y_hat = model(x_test)\n",
    "            loss = criterion(y_hat, y_test)\n",
    "            test_loss_history.append(float(loss.detach().cpu()))\n",
    "    test_loss = sum(test_loss_history) / len(test_loss_history)\n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        _ = torch.onnx.export(model, dummy_input, f'models/resnet34_{epoch}_{test_loss:.4f}.onnx', verbose=False)\n",
    "        print(f'test loss: {test_loss} (best, saving model)')\n",
    "    else:\n",
    "        print(f'test loss: {test_loss}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "jetbot-dl-model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}