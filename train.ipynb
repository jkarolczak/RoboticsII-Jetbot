{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "rnFsqbP6wSt7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from copy import deepcopy\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "ZHSMTSi3BmsN"
   },
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "\n",
    "# define your path below\n",
    "# DATASET_PATH = ... # Ania\n",
    "# DATASET_PATH = ... # Witek\n",
    "DATASET_PATH = 'dataset/'  # Jacek\n",
    "\n",
    "# hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "NUM_WORKERS = 1\n",
    "TRAIN_SET_SIZE = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "TEikNh9bW_s0"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "VN82Vw_KAdqw"
   },
   "outputs": [],
   "source": [
    "class StorageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path: str) -> None:\n",
    "        self.path = path\n",
    "        self.dirs = [d for d in os.listdir(self.path) if os.path.isdir(os.path.join(self.path, d))]\n",
    "        self.items = self._get_file_target_map()\n",
    "\n",
    "    def _get_file_target_map(self) -> List[Tuple[str, Tuple[float, float]]]:\n",
    "        result = []\n",
    "        for dir in self.dirs:\n",
    "            labels = pd.read_csv(f'{self.path}/{dir}.csv', header=None, index_col=0, names=['speed', 'turn'])\n",
    "            for file_name in os.listdir(os.path.join(self.path, dir)):\n",
    "                file_path = os.path.join(self.path, dir, file_name)\n",
    "                photo_id = int(re.search(r'\\d+', file_name).group())\n",
    "                if photo_id in labels.index:\n",
    "                    target = labels.loc[photo_id]\n",
    "                    result.append((file_path, (target['speed'], target['turn'], photo_id)))\n",
    "        return result\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        path, target = self.items[idx]\n",
    "        img = torch.tensor(np.asarray(Image.open(path)), dtype=torch.float32)\n",
    "        target = torch.tensor(target[:2], dtype=torch.float32)\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MemoryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path: str) -> None:\n",
    "        self.path = path\n",
    "        self.dirs = [d for d in os.listdir(self.path) if os.path.isdir(os.path.join(self.path, d))]\n",
    "        self.items = self._get_file_target_map()\n",
    "\n",
    "    def _get_file_target_map(self) -> List[Tuple[str, Tuple[float, float]]]:\n",
    "        result = []\n",
    "        for dir in self.dirs:\n",
    "            labels = pd.read_csv(f'{self.path}/{dir}.csv', header=None, index_col=0, names=['speed', 'turn'])\n",
    "            for file_name in os.listdir(os.path.join(self.path, dir)):\n",
    "                file_path = os.path.join(self.path, dir, file_name)\n",
    "                photo_id = int(re.search(r'\\d+', file_name).group())\n",
    "                if photo_id in labels.index:\n",
    "                    target = labels.loc[photo_id]\n",
    "                    img = Image.open(file_path)\n",
    "                    result.append((img, (target['speed'], target['turn'], photo_id)))\n",
    "        return result\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        img, target = self.items[idx]\n",
    "        img = torch.tensor(np.asarray(img), dtype=torch.float32)\n",
    "        target = torch.tensor(target[:2], dtype=torch.float32)\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "def train_test_split(dataset: Union[StorageDataset, MemoryDataset], train_size: float = 0.8, shuffle: bool = True):\n",
    "    train_keys, test_keys = set(), set()\n",
    "    train_items, test_items = list(), list()\n",
    "    for item in dataset.items:\n",
    "        key = item[1][2]\n",
    "        if key in train_keys:\n",
    "            train_items.append(item)\n",
    "        elif key in test_keys:\n",
    "            test_items.append(item)\n",
    "        else:\n",
    "            if np.random.random() < train_size:\n",
    "                train_keys.add(key)\n",
    "                train_items.append(item)\n",
    "            else:\n",
    "                test_keys.add(key)\n",
    "                test_items.append(item)\n",
    "    train, test = deepcopy(dataset), deepcopy(dataset)\n",
    "    train.items, test.items = train_items, test_items\n",
    "    return train, test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "jVJeCE8pO38l"
   },
   "outputs": [],
   "source": [
    "# dataset = StorageDataset(DATASET_PATH)\n",
    "dataset = MemoryDataset(DATASET_PATH)\n",
    "train_dataset, test_dataset = train_test_split(dataset, train_size=TRAIN_SET_SIZE, shuffle=True)\n",
    "train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "5mw2wrrHl-px"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.resnet18 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "        self.resnet18.fc = nn.Linear(in_features=512, out_features=2, bias=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = torch.movedim(x, -1, -3)\n",
    "        x = self.resnet18(x)\n",
    "        x = torch.clamp(x, min=-1.0, max=1.0)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "U0KsSWdmZNr2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jkarolczak/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "model.cuda()\n",
    "model = torch.jit.script(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "3hk-8VG8Tajg"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "5VE9Unb_UKXN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "train loss: 0.4879279392106192\n",
      "test loss: 0.4099640165056501\n",
      "epoch 1\n",
      "0/83\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [87]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     16\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     17\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m---> 18\u001B[0m     train_loss_history\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mfloat\u001B[39m(\u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetach\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcpu\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m))\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28msum\u001B[39m(train_loss_history) \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(train_loss_history)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     21\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train_len = len(train_dataset)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'epoch {epoch}')\n",
    "    train_loss_history, test_loss_history = [], []\n",
    "\n",
    "    model.train()\n",
    "    for i, (x_train, y_train) in enumerate(train):\n",
    "        if not i % 5:\n",
    "            print(f'{i}/{int(train_len / BATCH_SIZE)}', end='\\r')\n",
    "        x_train = x_train.to(torch.device('cuda'))\n",
    "        y_train = y_train.to(torch.device('cuda'))\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(x_train)\n",
    "        loss = criterion(y_hat, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_history.append(float(loss.detach().cpu()))\n",
    "    print(f'train loss: {sum(train_loss_history) / len(train_loss_history)}')\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x_test, y_test in test:\n",
    "            x_test = x_test.to(torch.device('cuda'))\n",
    "            y_test = y_test.to(torch.device('cuda'))\n",
    "            y_hat = model(x_test)\n",
    "            loss = criterion(y_hat, y_test)\n",
    "            test_loss_history.append(float(loss.detach().cpu()))\n",
    "    print(f'test loss: {sum(test_loss_history) / len(test_loss_history)}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "jetbot-dl-model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}